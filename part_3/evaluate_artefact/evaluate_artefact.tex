\section{Evaluate Artefact}
\subsection{Strategy and Method Choice}
To evaluate the artifact, it is necessary to validate that the requirements gathered in the earlier action, \emph{defining requirements}, have been met. The strategies considered for evaluation are Surveys, Experiments, Case studies, Ethnography, Theoretical Analysis. 
Doing an ethnographic study would give valuable insights into how an Internet of Things platform would be used and how our redesign would impact usage. 
Given that Internet of Things still isn't a widely adopted paradigm, the cultural impacts of MediaSense have no precedents with which to be compared. Such a study would only contribute to the understanding of how people use the Internet of Things and not our artifact specifically. A case study allows for a deep study of the artefact but can be biased by the researchers perceptions. Thus, doing a case study of an artifact developed earlier in the same research project will be inconclusive as to if the artifact actually fulfils the requirements. Experiments allow us to set up an artificial scenario. The experiment will be designed specifically to validate all the requirements. A drawback to using experiments is that the artificial scenario doesn't reflect a real life scenario. To rectify this, we will use Theoretical analysis of the results from the experiment. Thus, we chose to evaluate the artifact with experiments and theoretical analysis.

%\subsection{Research Question}
%\begin{quotation}
%How has the redesign of MediaSense affected the resource consumption and does it fulfil the requirements?
%\end{quotation}

\subsection{Method Application}
The research strategy used to evaluate the artefact was an experiment. The experiment was done by running an instance of the artefact and measure the memory usage while it is running. First the platform was started to see how much resources the platform use. When the platform was connected to the network, the researchers started to connect applications to the platform and take notes of how much memory every application was using. To test the old version of the middleware, a node farm was used. A bash script was used to start several applications where every application had its own MediaSense platform. 

A maximum of ten applications were connected to the platform when the researchers found a pattern in the resource usage. The data was then compared to data from the old artefact, where an analysis was done to see if the new version uses less memory. To see that all requirements were fulfilled different tests were done where every test had an expected result. All results were discussed among the researchers to address if the result matched the expected outcome, and to see if the requirements had been met. 

The experiment was done on an PC with operating system Ubuntu 12.04.2 LTS. The computer in use has an Intel Core i3-2350M processor and 8 GB Memory. To measure the resources the applications Gnome System Monitor 3.4.1 \cite{gnomesm} and htop 1.0.1 \cite{htop} was used. 

The non-functional requirements were not evaluated with a specific approach, they were discussed as the experiments took place to see that they were addressed and met. To test if the new artefact consumes less memory from the device one to ten applications were run with both the old version of the middleware and the redesigned version. The results were noted, and a comparison was then done. A test where platform and application were run on separate devices was also done to check the Gateway requirement.
